# CPU线程和TorchScript推理
PyTorch允许在使用TorchScript进行推理时使用CPU多线程.下图展示了在应用中会使用的不同级别的并行.

![img](https://github.com/shendeguize/PyTorchDocCN/blob/master/_imgs/0.3_0.png)

某一或者更多个线程执行某一个输入进入模型的前向操作时.每一个推理线程都会唤起一个即时编译器来逐行执行模型操作.模型可以利用`fork`的TorchScript来启动异步任务.forking若干操作就使得任务是并行执行的.`fork`操作返回的是一个可以被用于后续同步的`Future`对象,例如:
```Python
@torch.jit.script
def compute_z(x):
    return torch.mm(x, self.w_z)

@torch.jit.script
def forward(x):
    # launch compute_z asynchronously:
    # 协程启动compute_z:
    fut = torch.jit._fork(compute_z, x)
    # execute the next operation in parallel to compute_z:
    # 并行地执行下一个操作到compute_z:
    y = torch.mm(x, self.w_y)
    # wait for the result of compute_z:
    # 等待compute_Z的结果:
    z = torch.jit._wait(fut)
    return y + z
```
PyTorch对于操作内的并行使用的是一个单线程池,这个线程池被所有被fork的推理任务在应用过程中共享.

除了运算内并行,PyTorch也在运算间利用了多线程(intra-op并行).这在很多情况下都很有用,包括大张量的位操作,卷积,GEMM(矩阵乘法),embedding lookup(查询)和其他操作.

## build选择
PyTorch使用了内置的ATen库实现运算.此外,PyTorch同样可以基于外部库如[MKL](https://software.intel.com/en-us/mkl)和[MKL-DNN](https://github.com/intel/mkl-dnn)来构建以加速CPU运算.

ATen,MKL和MKL-DNN支持运算间并行,且实现依赖于下述并行库:
+ [OpenMP](https://www.openmp.org/)一个标准(也是一个库,常包含一个编译器),被外部库广泛使用.
+ [TBB](https://github.com/intel/tbb)一个稍新的,优化了基于任务并行和并发环境的库.

OpenMP一直以来被大量库使用.由于其易用性和对于基于循环的并行的支持以及其他特性而知名.

TBB相对而言在外部库中的使用少一些,但同时,对并发环境进行了优化.PyTorch的TBB后端保证了有每个进程的独立的单独运算间线程池被所有运行中的运算使用.

取决于使用情况,可能有其他并行库是更好的选择.

PyTorch允许在build时选择被ATen或其他库使用的并行后端,build选项包括:  
[详见原文档](https://pytorch.org/docs/1.5.0/notes/cpu_threading_torchscript_inference.html#build-options)
![img](https://github.com/shendeguize/PyTorchDocCN/blob/master/_imgs/0.3_1.png)
