# 自动求导机制
本文会概览自动梯度求导是如何工作和记录操作的.实际上并不是严格必要地理解全部内容,但是我们建议要熟悉他,因为这会有利于你写出更高效也更简明的程序并且帮助你debug.

## 从反向传播中排除子图
每个`Tensor`都有一个标签:`requires_grad`,这个标签使得我们能够细粒度地在计算梯度的过程中排除子图,并提升性能.

###  `requires_grad`
如果有对于一个运算有一个需要梯度的单独输入,那么对应的输出也需要梯度.与此相对,如果所有的输入都不需要梯度,那么输出也不需要.在所有的Tensor都不需要梯度时,反向传播计算是不会在子图中运算.

```Python3
>>> x = torch.randn(5, 5)  # requires_grad=False by default 默认为False
>>> y = torch.randn(5, 5)  # requires_grad=False by default
>>> z = torch.randn((5, 5), requires_grad=True)
>>> a = x + y
>>> a.requires_grad
False
>>> b = a + z
>>> b.requires_grad
True
```

对于你希望固定你的模型一部分时或者你已经知道一些参数是不需要参数的情况下这一方式尤其有效.例如你希望调整一个预训练的CNN时,对于固定的基础部分把`requires_grad`置为False就足够了,直到计算到最后一层需要保留梯度的权重的网络层前,中间计算缓存是不会被保留的.而最终网络的输出也是需要保留梯度的.

```Python3
model = torchvision.models.resnet18(pretrained=True)
for param in model.parameters():
    param.requires_grad = False
# Replace the last fully-connected layer
# Parameters of newly constructed modules have requires_grad=True by default
# 替换最后一层
# 新建Module的参数默认需要保留梯度
model.fc = nn.Linear(512, 100)

# Optimize only the classifier
optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)
```
## 自动求导机制是如何编码历史的
自动求导是一种反向自动差分系统.从概念上将,自动求导记录了一张图,这张图记录所有当你执行操作时产生数据的操作,这张图也是一个直接的非循环图,其叶子为输入张量而根为输出张量.通过从根到叶追踪这张图,就能依据链式法则自动计算梯度.

内在地,自动求导表示这张图是作为`Function`对象(表达式)的图,这张图能够被`apply()`调用以计算评估图的结果.在前向计算时,自动求导同事进行请求的计算和建立表示这个`function`的图以计算梯度(每个`torch.Tensor`的`.grad_fn`属性都是是这张图的的入口点).前向传播完成时,就会在反向计算时评估这张图来计算梯度.

需要注意的是这张计算图是在每个迭代中重新根据草图生成的,这容许使用任意的Python控制流语句,可以在每个迭代中改变图的形状尺寸等.不需要在开始训练前就编码所有可能的方式,所执行的就是所求导的.

## 原地操作与自动求导
支持原地操作的自动求导很难,我们在多数情况下不鼓励这样使用.自动求导积极缓存的释放和重用使得自动求导效率很高.很少有原地操作显著减少内存使用的情况.除非正在处理的运算有非常大的内存压力,应该不要使用原地操作.
这里有两条限制原地操作可用性的主要原因:
1. 原地操作可能会覆写梯度计算所需要的值
2. 每个原地操作实际上需要重写计算图的实现.非原位版本只需要声明新对象并且保留对旧有图的引用,而在原地操作中需要把所有的输入的创建者为`Function`来表示操作.这可能很躯壳,尤其在有对同一存储的多个引用张量时(例如通过索引或者转置等生成张量时).而且原地操作会在其试图修改被其他`Tensor`引用的存储是会报错.

## 原地正确性检查
每个张量都有一个版本计数器,每当在任何计算中被使用(原文marked dirty)时都会增加.当函数保存了任何张量以反向计算,所包含的张量的版本计数器也会被保存.一旦访问`self.saved_tensors`,计数器会被检查,如果大于比保存张量的计数器的话,会抛出异常.这确保了如果你使用了原地操作并且没有报错,你就能确定计算的梯度是正确的.



